=== 配置

NOTE: 以下配置三台主机都需要执行！

==== 创建用户

===== 创建用户
[source, bash]
----
useradd hadoop
----

===== 设置密码
[source, bash]
----
passwd hadoop
----

.终端输出
----
[root@node01 ~]# passwd hadoop
Changing password for user hadoop.
New password: #geek
BAD PASSWORD: The password is shorter than 8 characters
Retype new password: #geek
passwd: all authentication tokens updated successfully.
----

===== 配置用户权限
[source, bash]
----
vim /etc/sudoers 

#添加用户权限
......
## Allow root to run any commands anywhere 
root ALL=(ALL) ALL
hadoop  ALL=(ALL) ALL 
......

#保存退出
wq!
----

===== 使用用户
[source, bash]
----
su hadoop

#赋予Hadoop⽤户/⽤户组权限
sudo chown -R hadoop:hadoop /opt/module/hadoop
----

==== 配置环境变量

===== 创建配置⽂件
[source, bash]
----
cat <<EOF > /etc/profile.d/dfs.sh
# Java
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk 
export PATH=$PATH:$JAVA_HOME/bin

# Hadoop
export HADOOP_HOME=/opt/module/hadoop 
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
EOF
----

===== 使环境变量生效
[source, bash]
----
source /etc/profile
----

==== 配置Hadoop

===== 创建Hadoop工作目录
[source, bash]
----
mkdir /var/hd_data

sudo chown -R hadoop:hadoop /var/hd_data
----

===== 进入Hadoop主目录
[source, bash]
----
cd $HADOOP_HOME/etc/hadoop
----

===== hadoop-env.sh
[source, bash]
----
#54⾏
......
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk
......
----

===== yarn-env.sh
[source, bash]
----
#在尾部添加
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk
----

===== core-site.xml 
[source, bash]
----
sudo vim core-site.xml

<configuration>
	<property>
  		<name>fs.defaultFS</name>
  		<value>hdfs://node01:9000</value>
 	</property>
 	<property>
  		<name>hadoop.tmp.dir</name>
  		<value>/var/hd_data</value>
 	</property>
</configuration>
----

===== hdfs-site.xml
[source, bash]
----
sudo vim hdfs-site.xml

<configuration>
 	<property>
     		<name>dfs.replication</name>
     		<value>2</value>
 	</property>
 	<property>
     		<name>dfs.namenode.secondary.http-address</name>
     		<value>hdfs://node03:9868</value>
 	</property>
</configuration>
----

===== mapred-site.xml
[source, bash]
----
sudo vim mapred-site.xml
<configuration>
  	<property>
  		<name>mapreduce.framework.name</name>
  		<value>yarn</value>
 	</property>
</configuration>
----

===== yarn-site.xml
[source, bash]
----
sudo vim yarn-site.xml

<configuration>
<!-- Site specific YARN configuration properties -->
 	<property>
  		<name>yarn.nodemanager.aux-services</name>
	 	<value>mapreduce_shuffle</value>
 	</property>
 	<property>
  		<name>yarn.resourcemanager.hostname</name>
  		<value>node01</value>
 	</property>
</configuration>
----

===== workers
[source, bash]
----
cat <<EOF > /opt/module/hadoop/etc/hadoop/workers
node01
node02
node03
EOF
----

===== 添加hosts
[source, bash]
----
192.168.122.209 node01
192.168.122.210 node02
192.168.122.211 node03
----

==== 配置无密码登陆
[source, bash]
----
su hadoop

ssh-keygen -t rsa

ssh-copy-id node01
ssh-copy-id node02  
ssh-copy-id node03
----













